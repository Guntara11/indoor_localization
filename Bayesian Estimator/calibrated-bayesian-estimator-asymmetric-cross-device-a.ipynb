{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"calibrated-bayesian-estimator-asymmetric-cross-device-a.ipynb","provenance":[],"authorship_tag":"ABX9TyONYdXCXjUiINONW34bL384"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"11y9nS6TMEt3"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"jhH5YIsvLP_o","executionInfo":{"status":"ok","timestamp":1655907338335,"user_tz":-420,"elapsed":3,"user":{"displayName":"M Evan Anindya Wahyuaji","userId":"13562055425831538774"}}},"outputs":[],"source":["import numpy as np\n","from math import sqrt\n","import csv as commaSeparatedValues\n","# Inisiasi variabel-variabel\n","devices = [\"C20\", \"Evan\", \"Alba\"]\n","base_raw_directory = '/content/drive/My Drive/Capstone/Dirapikan/'\n","base_save_directory = '/content/drive/My Drive/Capstone/Spreadsheet/Bayesian Estimator Lintas Perangkat/'\n","# Indexing tingkat 1: device. Tingkat 3: Tx\n","rssi = np.empty([3, 6, 2, 6, 7, 200], dtype=int)\n","# Indexing tingkat 1: device. Tingkat 3: Tx. Tingkat 6: 0 = max, 1 = median, 2 = mean\n","rssi_centering = np.empty([3, 6, 2, 6, 7, 3], dtype=float)\n","# Indexing tingkat 1: device. Tingkat 2: Tx. Tingkat 3: data centering\n","centering_max = np.empty([3, 2, 3], dtype=float)\n","centering_min = np.empty([3, 2, 3], dtype=float)\n","# Indexing tingkat 3: data centering\n","bayesianLikelihood = np.empty([6, 7, 3], dtype=float)\n","# Variabel untuk keluaran ke .csv\n","fields = ['Distribusi Kekuatan Transmisi', 'Tipe Pusatan Data', 'Rerata Galat (meter)', 'Standar Deviasi Galat', 'ECDF 95% Galat (meter)']\n","row = np.empty(shape=(5), dtype='object')"]},{"cell_type":"code","source":["# Mounting Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"LXpCh1FzMH3L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655907369478,"user_tz":-420,"elapsed":26998,"user":{"displayName":"M Evan Anindya Wahyuaji","userId":"13562055425831538774"}},"outputId":"d6378809-6080-4d65-dc1e-e6546db5b932"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["#@title Form Parameter\n","training_device = \"C20\"  #@param [\"C20\", \"Evan\", \"Alba\"]\n","if training_device == \"C20\":\n","    trainingDeviceIndex = 0\n","elif training_device == \"Evan\":\n","    trainingDeviceIndex = 1\n","else:\n","    trainingDeviceIndex = 2\n","trainingRatio = 0.8 #@param {type:\"slider\", min:0.05, max:0.95, step:0.05}\n","trainingLength = int(trainingRatio*200)\n","distanceOrder = 2 #@param {type:\"number\"}\n","windowLength =  7#@param {tipe: \"integer\"}\n","# Indexing tingkat 4: data centering. Tingkat 5: 0 = ordinat perkiraan, 1 = axis perkiraan, 2 = galat (meter)\n","prediction = np.empty([6, 7, (201 - windowLength) * 3 - trainingLength, 3, 3], dtype=float)"],"metadata":{"id":"ZWMWaDIWMKdH","executionInfo":{"status":"ok","timestamp":1655907379368,"user_tz":-420,"elapsed":365,"user":{"displayName":"M Evan Anindya Wahyuaji","userId":"13562055425831538774"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# Exhaustive Search Akurasi per Distribusi Daya Transmisi"],"metadata":{"id":"X_ap3XpEN1CP"}},{"cell_type":"code","source":["# Kalau .csv-nya belum created aja\n","with open(base_save_directory + devices[trainingDeviceIndex] + \" 80-20 Power \" + str(distanceOrder) + \" Window \" + str(windowLength) + \".csv\", 'w', newline='') as csvFile:\n","    csvWriter = commaSeparatedValues.writer(csvFile)\n","    csvWriter.writerow(fields)\n","    csvFile.close()"],"metadata":{"id":"rqbiiijhO8GD","executionInfo":{"status":"ok","timestamp":1655863440739,"user_tz":-420,"elapsed":356,"user":{"displayName":"M Evan Anindya Wahyuaji","userId":"13562055425831538774"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Definisi fungsi pembantu\n","def normalize(ndarray, device, tx, centering_type):\n","    return (ndarray - centering_min[device, tx, centering_type])/(centering_max[device, tx, centering_type] - centering_min[device, tx, centering_type])\n","def search(tx):\n","    for axis in range(7):\n","        for ordinate in range(6):\n","            test_number = 0\n","            for device in range(3):\n","                if (device != trainingDeviceIndex):\n","                    test_data_range = range(201-windowLength)\n","                else:\n","                    test_data_range = range(trainingLength, 201-windowLength)\n","                for device_test_number in test_data_range:\n","                    for calc_axis in range(7):\n","                        for calc_ordinate in range(6):\n","                            rp_data = np.empty([6], dtype=float)\n","                            test_data = np.empty([6], dtype=float)\n","                            distance_power = np.empty([3], dtype=float)\n","                            var = np.zeros([3], dtype=float)\n","                            # Max\n","                            for beacon in range(6):\n","                                rp_data[beacon] = rssi_centering[trainingDeviceIndex, beacon, tx[beacon], calc_ordinate, calc_axis, 0]\n","                                test_data[beacon] = np.max(normalize(rssi[device, beacon, tx[beacon], ordinate, axis, device_test_number:windowLength+device_test_number], device, tx[beacon], 0))\n","                                var[0] += np.var(normalize(rssi[trainingDeviceIndex, beacon, tx[beacon], calc_ordinate, calc_axis, 0:trainingLength], trainingDeviceIndex, tx[beacon], 0))\n","                            distance_power[0] = np.sum(abs(rp_data-test_data)**distanceOrder)/6\n","                            var[0] /= 6\n","                            # Median\n","                            for beacon in range(6):\n","                                rp_data[beacon] = rssi_centering[trainingDeviceIndex, beacon, tx[beacon], calc_ordinate, calc_axis, 1]\n","                                test_data[beacon] = np.median(normalize(rssi[device, beacon, tx[beacon], ordinate, axis, device_test_number:windowLength+device_test_number], device, tx[beacon], 1))\n","                                var[1] += np.var(normalize(rssi[trainingDeviceIndex, beacon, tx[beacon], calc_ordinate, calc_axis, 0:trainingLength], trainingDeviceIndex, tx[beacon], 1))\n","                            distance_power[1] = np.sum(abs(rp_data-test_data)**distanceOrder)/6\n","                            var[1] /= 6\n","                            # Mean\n","                            for beacon in range(6):\n","                                rp_data[beacon] = rssi_centering[trainingDeviceIndex, beacon, tx[beacon], calc_ordinate, calc_axis, 2]\n","                                test_data[beacon] = np.mean(normalize(rssi[device, beacon, tx[beacon], ordinate, axis, device_test_number:windowLength+device_test_number], device, tx[beacon], 2))\n","                                var[2] += np.var(normalize(rssi[trainingDeviceIndex, beacon, tx[beacon], calc_ordinate, calc_axis, 0:trainingLength], trainingDeviceIndex, tx[beacon], 2))\n","                            distance_power[2] = np.sum(abs(rp_data-test_data)**distanceOrder)/6\n","                            var[2] /= 6\n","                            bayesianLikelihood[calc_ordinate, calc_axis, :] = np.exp(np.divide(-0.5*distance_power**(2/distanceOrder), var))\n","                    # Max\n","                    coordinate = np.unravel_index(np.argmax(bayesianLikelihood[:, :, 0]), (6, 7))\n","                    prediction[ordinate, axis, test_number, 0, 0] = coordinate[0]\n","                    prediction[ordinate, axis, test_number, 0, 1] = coordinate[1]\n","                    prediction[ordinate, axis, test_number, 0, 2] = sqrt((coordinate[0]-ordinate)**2 + (coordinate[1]-axis)**2)\n","                    # Median\n","                    coordinate = np.unravel_index(np.argmax(bayesianLikelihood[:, :, 1]), (6, 7))\n","                    prediction[ordinate, axis, test_number, 1, 0] = coordinate[0]\n","                    prediction[ordinate, axis, test_number, 1, 1] = coordinate[1]\n","                    prediction[ordinate, axis, test_number, 1, 2] = sqrt((coordinate[0]-ordinate)**2 + (coordinate[1]-axis)**2)\n","                    # Mean\n","                    coordinate = np.unravel_index(np.argmax(bayesianLikelihood[:, :, 2]), (6, 7))\n","                    prediction[ordinate, axis, test_number, 2, 0] = coordinate[0]\n","                    prediction[ordinate, axis, test_number, 2, 1] = coordinate[1]\n","                    prediction[ordinate, axis, test_number, 2, 2] = sqrt((coordinate[0]-ordinate)**2 + (coordinate[1]-axis)**2)\n","                    test_number += 1\n","def tx_to_str(tx):\n","    if(tx == 0):\n","        return \"-4\"\n","    elif(tx == 1):\n","        return \"-12\"\n","    else:\n","        return \"error\"\n","# Membaca csv dan pemusatan data training\n","for device in range(3):\n","    for axis in range(7):\n","        for ordinate in range(6):\n","            csv4 = np.genfromtxt(base_raw_directory + devices[device] + '/' + str(axis) + ',' + str(ordinate) + \"_\" + devices[device] + \".csv\", delimiter=',', case_sensitive=False)\n","            csv12 = np.genfromtxt(base_raw_directory + devices[device] + '-12/' + str(axis) + ',' + str(ordinate) + \"_\" + devices[device] + \"-12.csv\", delimiter=',', case_sensitive=False)\n","            for tx in range(2):\n","                for beacon in range(6):\n","                    if tx == 0:\n","                        rssi[device, beacon, 0, ordinate, axis, :] = csv4[beacon,5:205]\n","                    else:\n","                        rssi[device, beacon, 1, ordinate, axis, :] = csv12[beacon,5:205]\n","                    if device == trainingDeviceIndex:\n","                        rssi_centering[device, beacon, tx, ordinate, axis, 0] = np.max(rssi[device, beacon, tx, ordinate, axis, 0:trainingLength])\n","                        rssi_centering[device, beacon, tx, ordinate, axis, 1] = np.median(rssi[device, beacon, tx, ordinate, axis, 0:trainingLength])\n","                        rssi_centering[device, beacon, tx, ordinate, axis, 2] = np.mean(rssi[device, beacon, tx, ordinate, axis, 0:trainingLength])\n","                    else:\n","                        rssi_centering[device, beacon, tx, ordinate, axis, 0] = np.max(rssi[device, beacon, tx, ordinate, axis, :])\n","                        rssi_centering[device, beacon, tx, ordinate, axis, 1] = np.median(rssi[device, beacon, tx, ordinate, axis, :])\n","                        rssi_centering[device, beacon, tx, ordinate, axis, 2] = np.mean(rssi[device, beacon, tx, ordinate, axis, :])\n","    for tx in range(2):\n","        centering_max[device, tx, 0] = np.max(rssi_centering[device, :, tx, :, :, 0])\n","        centering_max[device, tx, 1] = np.max(rssi_centering[device, :, tx, :, :, 1])\n","        centering_max[device, tx, 2] = np.max(rssi_centering[device, :, tx, :, :, 2])\n","        centering_min[device, tx, 0] = np.min(rssi_centering[device, :, tx, :, :, 0])\n","        centering_min[device, tx, 1] = np.min(rssi_centering[device, :, tx, :, :, 1])\n","        centering_min[device, tx, 2] = np.min(rssi_centering[device, :, tx, :, :, 2])\n","        if device == 2:\n","            tdi = trainingDeviceIndex\n","            rssi_centering[tdi, :, tx, :, :, 0] = normalize(rssi_centering[tdi, :, tx, :, :, 0], tdi, tx, 0)\n","            rssi_centering[tdi, :, tx, :, :, 1] = normalize(rssi_centering[tdi, :, tx, :, :, 1], tdi, tx, 1)\n","            rssi_centering[tdi, :, tx, :, :, 2] = normalize(rssi_centering[tdi, :, tx, :, :, 2], tdi, tx, 2)\n","# Mengukur rerata dan persentil 95 galat pada setiap kombinasi distribusi daya dan pemusatan data\n","counter = 0\n","for tx1 in range(2):\n","    for tx2 in range(2):\n","        for tx3 in range(2):\n","            for tx4 in range(2):\n","                for tx5 in range(2):\n","                    for tx6 in range(2):\n","                        if counter > 134:\n","                            print(\"calculating \" + tx_to_str(tx1) + \", \" + tx_to_str(tx2) + \", \" + tx_to_str(tx3) + \", \" + tx_to_str(tx4) + \", \" + tx_to_str(tx5) + \", \" + tx_to_str(tx6))\n","                            search([tx1, tx2, tx3, tx4, tx5, tx6])\n","                        for centeringType in range(3):\n","                            if counter <= 134:\n","                                counter += 1\n","                                continue\n","                            print(counter)\n","                            row[0] = tx_to_str(tx1) + \", \" + tx_to_str(tx2) + \", \" + tx_to_str(tx3) + \", \" + tx_to_str(tx4) + \", \" + tx_to_str(tx5) + \", \" + tx_to_str(tx6)\n","                            if(centeringType == 0):\n","                                row[1] = \"Max\"\n","                            elif(centeringType == 1):\n","                                row[1] = \"Median\"\n","                            elif(centeringType == 2):\n","                                row[1] = \"Mean\"\n","                            else:\n","                                row[1] = \"Error\"\n","                            row[2] = np.mean(prediction[:, :, :, centeringType, 2])\n","                            row[3] = np.std(prediction[:, :, :, centeringType, 2])\n","                            row[4] = np.percentile(prediction[:, :, :, centeringType, 2], 95)\n","                            # Append keluaran ke .csv\n","                            with open(base_save_directory + devices[trainingDeviceIndex] + \" 80-20 Power \" + str(distanceOrder) + \" Window \" + str(windowLength) + \".csv\", 'a', newline='') as csvFile:\n","                                csvWriter = commaSeparatedValues.writer(csvFile)\n","                                csvWriter.writerow(row)\n","                                csvFile.close()\n","                            counter += 1"],"metadata":{"id":"slVBU8F2N5dL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655929275909,"user_tz":-420,"elapsed":21891600,"user":{"displayName":"M Evan Anindya Wahyuaji","userId":"13562055425831538774"}},"outputId":"bc77c463-a3de-4152-bc35-78b0ee89bf5c"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["calculating -12, -4, -12, -12, -4, -12\n","135\n","136\n","137\n","calculating -12, -4, -12, -12, -12, -4\n","138\n","139\n","140\n","calculating -12, -4, -12, -12, -12, -12\n","141\n","142\n","143\n","calculating -12, -12, -4, -4, -4, -4\n","144\n","145\n","146\n","calculating -12, -12, -4, -4, -4, -12\n","147\n","148\n","149\n","calculating -12, -12, -4, -4, -12, -4\n","150\n","151\n","152\n","calculating -12, -12, -4, -4, -12, -12\n","153\n","154\n","155\n","calculating -12, -12, -4, -12, -4, -4\n","156\n","157\n","158\n","calculating -12, -12, -4, -12, -4, -12\n","159\n","160\n","161\n","calculating -12, -12, -4, -12, -12, -4\n","162\n","163\n","164\n","calculating -12, -12, -4, -12, -12, -12\n","165\n","166\n","167\n","calculating -12, -12, -12, -4, -4, -4\n","168\n","169\n","170\n","calculating -12, -12, -12, -4, -4, -12\n","171\n","172\n","173\n","calculating -12, -12, -12, -4, -12, -4\n","174\n","175\n","176\n","calculating -12, -12, -12, -4, -12, -12\n","177\n","178\n","179\n","calculating -12, -12, -12, -12, -4, -4\n","180\n","181\n","182\n","calculating -12, -12, -12, -12, -4, -12\n","183\n","184\n","185\n","calculating -12, -12, -12, -12, -12, -4\n","186\n","187\n","188\n","calculating -12, -12, -12, -12, -12, -12\n","189\n","190\n","191\n"]}]},{"cell_type":"code","source":["drive.flush_and_unmount()"],"metadata":{"id":"ku9aTkTvN5CC"},"execution_count":null,"outputs":[]}]}